{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce065a1-d073-4c7b-95a0-2b58be92d2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.formula.api as smf\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db4487da-3102-4968-8484-eef81a288059",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_filtered = pd.read_csv('data/filtered_experiment_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349af6d0-6467-4c7e-8d6c-c7603d66f976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language  Literal_was  Fixed_was  Literal_pwld  Fixed_pwld\n",
      "0       bg     3.175256   3.221264      0.204141    0.252588\n",
      "1       be     3.235893   3.249172      0.212757    0.219716\n",
      "2       cs     3.323028   3.382418      0.174754    0.291087\n",
      "3       pl     3.332122   3.388665      0.207772    0.297607\n",
      "4       uk     3.257236   3.298384      0.197653    0.210293\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "languages = ['BG', 'BE', 'CS', 'PL', 'UK']\n",
    "\n",
    "# Initialize dictionaries to store the dataframes\n",
    "was_data, pwld_data = {}, {}\n",
    "agg_was, agg_pwld = [], []\n",
    "\n",
    "for l2 in languages:\n",
    "    l2_lower = l2.lower()\n",
    "    \n",
    "    # Load and process WAS data\n",
    "    was_df = pd.read_csv(f'data/metrics/was/was_literal_{l2_lower}_ru.csv')\n",
    "    was_fixed_df = pd.read_csv(f'data/metrics/was/was_fixed_{l2_lower}_ru.csv')\n",
    "    was_df['normalized WAS fixed'] = was_fixed_df['normalized WAS']\n",
    "    was_data[f'{l2_lower}_ru'] = was_df\n",
    "    agg_was.append({\n",
    "        'Language': l2_lower,\n",
    "        'Literal_was': np.mean(was_df['normalized WAS']),\n",
    "        'Fixed_was': np.mean(was_df['normalized WAS fixed'])\n",
    "    })\n",
    "    \n",
    "    # Load and process PWLD data\n",
    "    pwld_df = pd.read_csv(f'data/metrics/pwld/pwld_dict_literal_ru_{l2_lower}.csv')\n",
    "    pwld_fixed_df = pd.read_csv(f'data/metrics/pwld/pwld_dict_fixed_ru_{l2_lower}.csv')\n",
    "    pwld_df['Value fixed'] = pwld_fixed_df['Value']\n",
    "    pwld_data[f'ru_{l2_lower}'] = pwld_df\n",
    "    agg_pwld.append({\n",
    "        'Language': l2_lower,\n",
    "        'Literal_pwld': np.mean(pwld_df['Value']),\n",
    "        'Fixed_pwld': np.mean(pwld_df['Value fixed'])\n",
    "    })\n",
    "\n",
    "# Convert aggregated data to DataFrames and merge\n",
    "was_df = pd.DataFrame(agg_was)\n",
    "pwld_df = pd.DataFrame(agg_pwld)\n",
    "merged_df = pd.merge(was_df, pwld_df, on='Language')\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e6140b3-47e6-460d-97f3-d32f222e5bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = {}\n",
    "models = ['model_gpt_small', 'model_bert_small', 'model_gpt_large', 'model_bert_large']\n",
    "columns = ['phrase ru', 'surprisal_sentence ru', 'literal translation', 'surprisal_phrase ru with literal']\n",
    "\n",
    "\n",
    "for lang in languages:\n",
    "    for model_name in models:\n",
    "        file_path = f\"data/metrics/surprisal/{lang}_{model_name}_data.csv\"\n",
    "        \n",
    "        # Load the data into a DataFrame\n",
    "        df = pd.read_csv(file_path, usecols=columns)\n",
    "        \n",
    "        # Filter out rows where any of the desired columns are missing\n",
    "        df = df.dropna(subset=columns)\n",
    "        \n",
    "        # Save to the results dictionary\n",
    "        results[(lang, model_name)] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d412f878-6a07-45d1-b4be-fdcb088cc7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import ast\n",
    "# Extending the punctuation list\n",
    "extended_punctuation = string.punctuation + '…'\n",
    "\n",
    "# Updated function to remove punctuation from a given word\n",
    "def remove_punctuation(word):\n",
    "    return ''.join(ch for ch in word if ch not in extended_punctuation)\n",
    "\n",
    "# Updated function to compute average surprisal\n",
    "def compute_average_surprisal(phrase, surprisal_str):\n",
    "    try:\n",
    "        # Convert string to dictionary\n",
    "        surprisal_dict = ast.literal_eval(surprisal_str)\n",
    "        # Clean keys in surprisal_dict (removing punctuation)\n",
    "        surprisal_dict = {remove_punctuation(key): value for key, value in surprisal_dict.items()}\n",
    "        # Get the tokens from the phrase\n",
    "        tokens = remove_punctuation(phrase).split()\n",
    "        # Compute average surprisal for the tokens in the phrase\n",
    "        total_surprisal = sum(surprisal_dict.get(token, float('nan')) for token in tokens)\n",
    "        return total_surprisal / len(tokens)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return float('nan')\n",
    "\n",
    "for key, df in results.items():\n",
    "    # Calculate average surprisal for 'phrase ru'\n",
    "    df['avg_surprisal_phrase ru'] = df.apply(lambda row: compute_average_surprisal(row['phrase ru'], row['surprisal_sentence ru']), axis=1)\n",
    "    # Calculate average surprisal for 'literal translation'\n",
    "    df['avg_surprisal_literal'] = df.apply(lambda row: compute_average_surprisal(row['literal translation'], row['surprisal_phrase ru with literal']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd1996f5-b381-4e90-8214-4715cc363aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a combined dataframe\n",
    "dfs = []\n",
    "for model_name in models:\n",
    "    for lang in languages:\n",
    "        temp_df = results[(lang, model_name)].copy()\n",
    "        temp_df['language'] = lang\n",
    "        temp_df['model'] = model_name\n",
    "        dfs.append(temp_df)\n",
    "combined_df = pd.concat(dfs)\n",
    "\n",
    "# Melt the dataframe to transform it for plotting\n",
    "df_melted = combined_df.melt(id_vars=[\"language\", \"model\"], \n",
    "                             value_vars=[\"avg_surprisal_phrase ru\", \"avg_surprisal_literal\"],\n",
    "                             var_name=\"Metric\",\n",
    "                             value_name=\"Surprisal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a1927bb-f784-4092-a80b-de8c6907744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'language' and 'model', then calculate the mean of 'Surprisal' for each group\n",
    "average_surprisal = df_melted.groupby(['language', 'model', 'Metric'])['Surprisal'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc3fcdc5-7bec-4ae9-9cd4-eeb5299f0173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_metric language  model_bert_large_literal  model_bert_large_phrase  \\\n",
      "0                  BE                  6.161847                 0.815297   \n",
      "1                  BG                  7.459920                 1.027850   \n",
      "2                  CS                  7.003779                 1.139527   \n",
      "3                  PL                  6.403018                 1.037337   \n",
      "4                  UK                  6.512173                 0.787037   \n",
      "\n",
      "model_metric  model_bert_small_literal  model_bert_small_phrase  \\\n",
      "0                            16.660070                15.648769   \n",
      "1                            15.376191                15.444899   \n",
      "2                            16.695863                15.992625   \n",
      "3                            17.255480                16.992005   \n",
      "4                            16.416540                16.380210   \n",
      "\n",
      "model_metric  model_gpt_large_literal  model_gpt_large_phrase  \\\n",
      "0                            7.130234                3.332662   \n",
      "1                            7.723927                3.707474   \n",
      "2                            7.328689                3.695524   \n",
      "3                            7.494197                3.519089   \n",
      "4                            7.332158                3.411002   \n",
      "\n",
      "model_metric  model_gpt_small_literal  model_gpt_small_phrase  \n",
      "0                            7.184592                3.557769  \n",
      "1                            7.631683                3.983022  \n",
      "2                            7.258239                3.758246  \n",
      "3                            7.552764                3.725802  \n",
      "4                            7.307725                3.572677  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(average_surprisal)\n",
    "\n",
    "# Add prefixes to the 'Metric' values\n",
    "df['Metric'] = df['Metric'].apply(lambda x: '_literal' if 'literal' in x else '_phrase')\n",
    "\n",
    "# Create a new column combining 'model' and 'Metric'\n",
    "df['model_metric'] = df['model'] + df['Metric']\n",
    "\n",
    "# Pivot the data: 'model_metric' values become new columns, filled with 'Surprisal' values\n",
    "pivoted_df = df.pivot(index='language', columns='model_metric', values='Surprisal').reset_index()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(pivoted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea19d178-77e4-42ab-83d6-36f613160fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df['language'] = pivoted_df['language'].str.lower()\n",
    "merged_df['Language'] = merged_df['Language'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "62d3d030-0782-42eb-be51-942221607149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(experiment_filtered)\n",
    "\n",
    "# Calculating the percentage of correct responses per 'source_text_to_be_translated'\n",
    "correct_percentage = df.groupby(['source_text_to_be_translated', 'source_language'])['is_correct'].mean() * 100\n",
    "\n",
    "# Converting to DataFrame for better visualization\n",
    "correct_percentage_df = correct_percentage.reset_index()\n",
    "\n",
    "# Renaming columns for clarity\n",
    "correct_percentage_df.columns = ['source_text_to_be_translated', 'language', 'correct_percentage']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9d103220-835b-4b01-9d74-3bb74ea2e727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_text_to_be_translated</th>\n",
       "      <th>language</th>\n",
       "      <th>correct_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a navíc</td>\n",
       "      <td>CS</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a tu</td>\n",
       "      <td>PL</td>\n",
       "      <td>27.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a zasię</td>\n",
       "      <td>PL</td>\n",
       "      <td>82.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>albo i</td>\n",
       "      <td>PL</td>\n",
       "      <td>56.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ale przecież</td>\n",
       "      <td>PL</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>ў сілу</td>\n",
       "      <td>BE</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>ўбок</td>\n",
       "      <td>BE</td>\n",
       "      <td>53.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>ўсе жыцце</td>\n",
       "      <td>BE</td>\n",
       "      <td>88.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>ўсе роўна</td>\n",
       "      <td>BE</td>\n",
       "      <td>92.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>ўсяго толькi</td>\n",
       "      <td>BE</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    source_text_to_be_translated language  correct_percentage\n",
       "0                        a navíc       CS           40.000000\n",
       "1                           a tu       PL           27.272727\n",
       "2                        a zasię       PL           82.608696\n",
       "3                         albo i       PL           56.666667\n",
       "4                   ale przecież       PL           30.000000\n",
       "..                           ...      ...                 ...\n",
       "288                       ў сілу       BE          100.000000\n",
       "289                         ўбок       BE           53.846154\n",
       "290                    ўсе жыцце       BE           88.461538\n",
       "291                    ўсе роўна       BE           92.592593\n",
       "292                 ўсяго толькi       BE           37.500000\n",
       "\n",
       "[293 rows x 3 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_percentage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "73c8332d-abed-463b-8e9f-8057f4b5d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new columns for checking if the translations are correct\n",
    "experiment_filtered['is_correct_mcq'] = experiment_filtered['user_mcq_translation'] == experiment_filtered['correct_translation']\n",
    "experiment_filtered['is_correct_free'] = experiment_filtered['user_free_translation'] == experiment_filtered['correct_translation']\n",
    "\n",
    "# Counting the number of correct translations by language for each type of translation\n",
    "correct_counts_mcq = experiment_filtered.groupby('source_language')['is_correct_mcq'].sum().reset_index()\n",
    "correct_counts_free = experiment_filtered.groupby('source_language')['is_correct_free'].sum().reset_index()\n",
    "\n",
    "# Calculating the percentage of correct translations\n",
    "total_counts = experiment_filtered['source_language'].value_counts().reset_index()\n",
    "total_counts.columns = ['source_language', 'total']\n",
    "\n",
    "# Merging and calculating the percentage for MCQ translations\n",
    "correct_counts_mcq = pd.merge(correct_counts_mcq, total_counts, on='source_language')\n",
    "correct_counts_mcq['correct_percentage_mcq'] = (correct_counts_mcq['is_correct_mcq'] / correct_counts_mcq['total']) * 100\n",
    "\n",
    "# Merging and calculating the percentage for free translations\n",
    "correct_counts_free = pd.merge(correct_counts_free, total_counts, on='source_language')\n",
    "correct_counts_free['correct_percentage_free'] = (correct_counts_free['is_correct_free'] / correct_counts_free['total']) * 100\n",
    "\n",
    "# Merging the two results into a single DataFrame\n",
    "final_correct_counts = pd.merge(correct_counts_mcq, correct_counts_free, on=['source_language', 'total'])\n",
    "# Rename the column\n",
    "final_correct_counts = final_correct_counts.rename(columns={'source_language': 'language'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24789cc0-2c0c-4944-a6f3-c5df63991022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge while converting 'Language' to lowercase on the fly\n",
    "final_merged_df = pd.merge(pivoted_df, merged_df, left_on='language', right_on=merged_df['Language'].str.lower(), how='inner')\n",
    "\n",
    "# Optionally, drop the redundant column\n",
    "final_merged_df = final_merged_df.drop(columns=['Language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "482fa4fd-3b92-4725-853b-f163b5c54839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge final_merged_df with final_correct_counts on the language column\n",
    "final_df = pd.merge(final_merged_df, final_correct_counts, left_on='language', right_on=merged_df['Language'].str.lower(), how='left')\n",
    "final_df = final_df.drop(columns=['language_x', 'is_correct_mcq', 'total', 'language_y', 'is_correct_free'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "20409e2e-9b1f-4bf2-9afe-2eef384e7ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>model_bert_large_literal</th>\n",
       "      <th>model_bert_large_phrase</th>\n",
       "      <th>model_bert_small_literal</th>\n",
       "      <th>model_bert_small_phrase</th>\n",
       "      <th>model_gpt_large_literal</th>\n",
       "      <th>model_gpt_large_phrase</th>\n",
       "      <th>model_gpt_small_literal</th>\n",
       "      <th>model_gpt_small_phrase</th>\n",
       "      <th>Literal_was</th>\n",
       "      <th>Fixed_was</th>\n",
       "      <th>Literal_pwld</th>\n",
       "      <th>Fixed_pwld</th>\n",
       "      <th>correct_percentage_mcq</th>\n",
       "      <th>correct_percentage_free</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be</td>\n",
       "      <td>6.161847</td>\n",
       "      <td>0.815297</td>\n",
       "      <td>16.660070</td>\n",
       "      <td>15.648769</td>\n",
       "      <td>7.130234</td>\n",
       "      <td>3.332662</td>\n",
       "      <td>7.184592</td>\n",
       "      <td>3.557769</td>\n",
       "      <td>3.235893</td>\n",
       "      <td>3.249172</td>\n",
       "      <td>0.212757</td>\n",
       "      <td>0.219716</td>\n",
       "      <td>74.546722</td>\n",
       "      <td>17.921897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bg</td>\n",
       "      <td>7.459920</td>\n",
       "      <td>1.027850</td>\n",
       "      <td>15.376191</td>\n",
       "      <td>15.444899</td>\n",
       "      <td>7.723927</td>\n",
       "      <td>3.707474</td>\n",
       "      <td>7.631683</td>\n",
       "      <td>3.983022</td>\n",
       "      <td>3.175256</td>\n",
       "      <td>3.221264</td>\n",
       "      <td>0.204141</td>\n",
       "      <td>0.252588</td>\n",
       "      <td>82.905983</td>\n",
       "      <td>29.273504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cs</td>\n",
       "      <td>7.003779</td>\n",
       "      <td>1.139527</td>\n",
       "      <td>16.695863</td>\n",
       "      <td>15.992625</td>\n",
       "      <td>7.328689</td>\n",
       "      <td>3.695524</td>\n",
       "      <td>7.258239</td>\n",
       "      <td>3.758246</td>\n",
       "      <td>3.323028</td>\n",
       "      <td>3.382418</td>\n",
       "      <td>0.174754</td>\n",
       "      <td>0.291087</td>\n",
       "      <td>59.795222</td>\n",
       "      <td>4.641638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pl</td>\n",
       "      <td>6.403018</td>\n",
       "      <td>1.037337</td>\n",
       "      <td>17.255480</td>\n",
       "      <td>16.992005</td>\n",
       "      <td>7.494197</td>\n",
       "      <td>3.519089</td>\n",
       "      <td>7.552764</td>\n",
       "      <td>3.725802</td>\n",
       "      <td>3.332122</td>\n",
       "      <td>3.388665</td>\n",
       "      <td>0.207772</td>\n",
       "      <td>0.297607</td>\n",
       "      <td>57.201087</td>\n",
       "      <td>11.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uk</td>\n",
       "      <td>6.512173</td>\n",
       "      <td>0.787037</td>\n",
       "      <td>16.416540</td>\n",
       "      <td>16.380210</td>\n",
       "      <td>7.332158</td>\n",
       "      <td>3.411002</td>\n",
       "      <td>7.307725</td>\n",
       "      <td>3.572677</td>\n",
       "      <td>3.257236</td>\n",
       "      <td>3.298384</td>\n",
       "      <td>0.197653</td>\n",
       "      <td>0.210293</td>\n",
       "      <td>80.999296</td>\n",
       "      <td>30.260380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language  model_bert_large_literal  model_bert_large_phrase  \\\n",
       "0       be                  6.161847                 0.815297   \n",
       "1       bg                  7.459920                 1.027850   \n",
       "2       cs                  7.003779                 1.139527   \n",
       "3       pl                  6.403018                 1.037337   \n",
       "4       uk                  6.512173                 0.787037   \n",
       "\n",
       "   model_bert_small_literal  model_bert_small_phrase  model_gpt_large_literal  \\\n",
       "0                 16.660070                15.648769                 7.130234   \n",
       "1                 15.376191                15.444899                 7.723927   \n",
       "2                 16.695863                15.992625                 7.328689   \n",
       "3                 17.255480                16.992005                 7.494197   \n",
       "4                 16.416540                16.380210                 7.332158   \n",
       "\n",
       "   model_gpt_large_phrase  model_gpt_small_literal  model_gpt_small_phrase  \\\n",
       "0                3.332662                 7.184592                3.557769   \n",
       "1                3.707474                 7.631683                3.983022   \n",
       "2                3.695524                 7.258239                3.758246   \n",
       "3                3.519089                 7.552764                3.725802   \n",
       "4                3.411002                 7.307725                3.572677   \n",
       "\n",
       "   Literal_was  Fixed_was  Literal_pwld  Fixed_pwld  correct_percentage_mcq  \\\n",
       "0     3.235893   3.249172      0.212757    0.219716               74.546722   \n",
       "1     3.175256   3.221264      0.204141    0.252588               82.905983   \n",
       "2     3.323028   3.382418      0.174754    0.291087               59.795222   \n",
       "3     3.332122   3.388665      0.207772    0.297607               57.201087   \n",
       "4     3.257236   3.298384      0.197653    0.210293               80.999296   \n",
       "\n",
       "   correct_percentage_free  \n",
       "0                17.921897  \n",
       "1                29.273504  \n",
       "2                 4.641638  \n",
       "3                11.005435  \n",
       "4                30.260380  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5533dd0f-9d8f-41d3-81ad-820edb57073b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              OLS Regression Results                              \n",
      "==================================================================================\n",
      "Dep. Variable:     correct_percentage_mcq   R-squared:                       1.000\n",
      "Model:                                OLS   Adj. R-squared:                    nan\n",
      "Method:                     Least Squares   F-statistic:                       nan\n",
      "Date:                    Sat, 14 Oct 2023   Prob (F-statistic):                nan\n",
      "Time:                            16:16:09   Log-Likelihood:                 145.41\n",
      "No. Observations:                       5   AIC:                            -280.8\n",
      "Df Residuals:                           0   BIC:                            -282.8\n",
      "Df Model:                               4                                         \n",
      "Covariance Type:                nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                  24.7784        inf          0        nan         nan         nan\n",
      "Literal_was               -91.0205        inf         -0        nan         nan         nan\n",
      "Fixed_pwld               -352.6533        inf         -0        nan         nan         nan\n",
      "Fixed_was                  82.5449        inf          0        nan         nan         nan\n",
      "model_gpt_small_literal     3.9380        inf          0        nan         nan         nan\n",
      "model_gpt_small_phrase     35.2157        inf          0        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.277\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                1.173\n",
      "Skew:                           1.185   Prob(JB):                        0.556\n",
      "Kurtosis:                       2.894   Cond. No.                     1.22e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The input rank is higher than the number of observations.\n",
      "[3] The condition number is large, 1.22e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n",
      "/usr/local/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:1794: RuntimeWarning: divide by zero encountered in divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/usr/local/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:1794: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/usr/local/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:1716: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Create a DataFrame\n",
    "df = final_df\n",
    "\n",
    "# List of potential predictor variables\n",
    "predictors = [\n",
    "    'model_bert_large_literal', 'model_bert_large_phrase',\n",
    "    'model_bert_small_literal', 'model_bert_small_phrase',\n",
    "    'model_gpt_large_literal', 'model_gpt_large_phrase',\n",
    "    'model_gpt_small_literal', 'model_gpt_small_phrase',\n",
    "    'Literal_was', 'Fixed_was', 'Literal_pwld', 'Fixed_pwld'\n",
    "]\n",
    "\n",
    "# Dependent variable\n",
    "dependent_var = 'correct_percentage_mcq'  # or 'correct_percentage_free'\n",
    "\n",
    "# Forward stepwise regression\n",
    "def forward_stepwise_regression(predictors, dependent_var, df):\n",
    "    remaining_predictors = set(predictors)\n",
    "    selected_predictors = []\n",
    "    current_score, best_new_score = float('inf'), float('inf')\n",
    "    \n",
    "    while remaining_predictors and current_score == best_new_score:\n",
    "        scores_with_predictors = []\n",
    "        for predictor in remaining_predictors:\n",
    "            formula = \"{} ~ {}\".format(dependent_var, ' + '.join(selected_predictors + [predictor]))\n",
    "            score = smf.ols(formula, df).fit().aic\n",
    "            scores_with_predictors.append((score, predictor))\n",
    "        scores_with_predictors.sort()\n",
    "        best_new_score, best_predictor = scores_with_predictors.pop(0)\n",
    "        if current_score > best_new_score:\n",
    "            remaining_predictors.remove(best_predictor)\n",
    "            selected_predictors.append(best_predictor)\n",
    "            current_score = best_new_score\n",
    "    formula = \"{} ~ {}\".format(dependent_var, ' + '.join(selected_predictors))\n",
    "    model = smf.ols(formula, df).fit()\n",
    "    return model\n",
    "\n",
    "# Run the stepwise regression\n",
    "model = forward_stepwise_regression(predictors, dependent_var, df)\n",
    "\n",
    "# Display the model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c6d49220-14b5-4de4-863a-7cafd80883de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>correct_percentage_mcq</td> <th>  R-squared:         </th> <td>   1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                      <td>OLS</td>          <th>  Adj. R-squared:    </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>Least Squares</td>     <th>  F-statistic:       </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                <td>Sat, 14 Oct 2023</td>    <th>  Prob (F-statistic):</th>  <td>   nan</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                    <td>16:17:59</td>        <th>  Log-Likelihood:    </th> <td>  145.41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>         <td>     5</td>         <th>  AIC:               </th> <td>  -280.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>             <td>     0</td>         <th>  BIC:               </th> <td>  -282.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                 <td>     4</td>         <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>nonrobust</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>   24.7784</td> <td>      inf</td> <td>        0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literal_was</th>             <td>  -91.0205</td> <td>      inf</td> <td>       -0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fixed_pwld</th>              <td> -352.6533</td> <td>      inf</td> <td>       -0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fixed_was</th>               <td>   82.5449</td> <td>      inf</td> <td>        0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>model_gpt_small_literal</th> <td>    3.9380</td> <td>      inf</td> <td>        0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>model_gpt_small_phrase</th>  <td>   35.2157</td> <td>      inf</td> <td>        0</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>   nan</td> <th>  Durbin-Watson:     </th> <td>   1.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td>   nan</td> <th>  Jarque-Bera (JB):  </th> <td>   1.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.185</td> <th>  Prob(JB):          </th> <td>   0.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.894</td> <th>  Cond. No.          </th> <td>1.22e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The input rank is higher than the number of observations.<br/>[3] The condition number is large, 1.22e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}             & correct\\_percentage\\_mcq & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}                     &           OLS            & \\textbf{  Adj. R-squared:    } &       nan   \\\\\n",
       "\\textbf{Method:}                    &      Least Squares       & \\textbf{  F-statistic:       } &       nan   \\\\\n",
       "\\textbf{Date:}                      &     Sat, 14 Oct 2023     & \\textbf{  Prob (F-statistic):} &      nan    \\\\\n",
       "\\textbf{Time:}                      &         16:17:59         & \\textbf{  Log-Likelihood:    } &    145.41   \\\\\n",
       "\\textbf{No. Observations:}          &               5          & \\textbf{  AIC:               } &    -280.8   \\\\\n",
       "\\textbf{Df Residuals:}              &               0          & \\textbf{  BIC:               } &    -282.8   \\\\\n",
       "\\textbf{Df Model:}                  &               4          & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}           &        nonrobust         & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                  &      24.7784  &          inf     &         0  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{Literal\\_was}               &     -91.0205  &          inf     &        -0  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{Fixed\\_pwld}                &    -352.6533  &          inf     &        -0  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{Fixed\\_was}                 &      82.5449  &          inf     &         0  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{model\\_gpt\\_small\\_literal} &       3.9380  &          inf     &         0  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{model\\_gpt\\_small\\_phrase}  &      35.2157  &          inf     &         0  &           nan        &          nan    &          nan     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &    nan & \\textbf{  Durbin-Watson:     } &    1.277  \\\\\n",
       "\\textbf{Prob(Omnibus):} &    nan & \\textbf{  Jarque-Bera (JB):  } &    1.173  \\\\\n",
       "\\textbf{Skew:}          &  1.185 & \\textbf{  Prob(JB):          } &    0.556  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.894 & \\textbf{  Cond. No.          } & 1.22e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The input rank is higher than the number of observations. \\newline\n",
       " [3] The condition number is large, 1.22e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                              OLS Regression Results                              \n",
       "==================================================================================\n",
       "Dep. Variable:     correct_percentage_mcq   R-squared:                       1.000\n",
       "Model:                                OLS   Adj. R-squared:                    nan\n",
       "Method:                     Least Squares   F-statistic:                       nan\n",
       "Date:                    Sat, 14 Oct 2023   Prob (F-statistic):                nan\n",
       "Time:                            16:17:59   Log-Likelihood:                 145.41\n",
       "No. Observations:                       5   AIC:                            -280.8\n",
       "Df Residuals:                           0   BIC:                            -282.8\n",
       "Df Model:                               4                                         \n",
       "Covariance Type:                nonrobust                                         \n",
       "===========================================================================================\n",
       "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "Intercept                  24.7784        inf          0        nan         nan         nan\n",
       "Literal_was               -91.0205        inf         -0        nan         nan         nan\n",
       "Fixed_pwld               -352.6533        inf         -0        nan         nan         nan\n",
       "Fixed_was                  82.5449        inf          0        nan         nan         nan\n",
       "model_gpt_small_literal     3.9380        inf          0        nan         nan         nan\n",
       "model_gpt_small_phrase     35.2157        inf          0        nan         nan         nan\n",
       "==============================================================================\n",
       "Omnibus:                          nan   Durbin-Watson:                   1.277\n",
       "Prob(Omnibus):                    nan   Jarque-Bera (JB):                1.173\n",
       "Skew:                           1.185   Prob(JB):                        0.556\n",
       "Kurtosis:                       2.894   Cond. No.                     1.22e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The input rank is higher than the number of observations.\n",
       "[3] The condition number is large, 1.22e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
